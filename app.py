import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image # <--- NUEVO: Herramienta para imÃ¡genes

# 1. ConfiguraciÃ³n de la PÃ¡gina
st.set_page_config(
    page_title="Profe Bot IA (Con Ojos)",
    page_icon="ðŸ‘ï¸â€ðŸ—¨ï¸",
    layout="centered"
)

# 2. Cargar llave de seguridad
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    st.error("âŒ Falta la API Key en el .env")
    st.stop()

genai.configure(api_key=api_key)

# 3. ConfiguraciÃ³n del Modelo
MODELO_A_USAR = "gemini-2.5-flash"

INSTRUCCIONES = """
Eres un profesor experto de Bachillerato, especializado en TecnologÃ­a.
Tu nombre es 'Profe Bot'.
Tus reglas de comportamiento son:
1. Explica todo con paciencia y usa un lenguaje cercano y motivador.
2. Usar analogÃ­as divertidas (ej. comparar cÃ³digo con recetas de cocina o videojuegos).
3. Ser paciente y motivador. Si el estudiante se equivoca, dile que es parte del aprendizaje.
4. Usa negritas para conceptos clave.
5. NUNCA des la respuesta directa a una tarea. GuÃ­a al estudiante con pistas para que piense.
6. Si el estudiante te saluda, presÃ©ntate y pregunta quÃ© quiere aprender hoy.
7. Usa emojis para hacer la clase divertida ðŸ’».
"""

# 4. Inicializar Chat
if "history" not in st.session_state:
    st.session_state.history = []

try:
    model = genai.GenerativeModel(MODELO_A_USAR, system_instruction=INSTRUCCIONES)
    chat = model.start_chat(history=st.session_state.history)
except Exception as e:
    st.error(f"Error de conexiÃ³n: {e}")

# 5. Interfaz GrÃ¡fica
st.title("ðŸ‘ï¸â€ðŸ—¨ï¸ Profe Bot: Ahora puedo ver")
st.caption("Sube una foto de tu tarea o duda")

# --- NUEVO: BARRA LATERAL PARA SUBIR IMÃGENES ---
with st.sidebar:
    st.header("ðŸ“¸ Sube tu imagen aquÃ­")
    archivo_subido = st.file_uploader("Elige una foto...", type=["jpg", "jpeg", "png"])
    
    imagen_para_procesar = None
    if archivo_subido is not None:
        # Mostramos la imagen en pequeÃ±ito
        imagen_para_procesar = Image.open(archivo_subido)
        st.image(imagen_para_procesar, caption="Imagen cargada", use_container_width=True)
        st.success("Â¡Imagen lista para analizar!")

st.markdown("---")

# 6. Mostrar historial
for message in chat.history:
    role = "user" if message.role == "user" else "assistant"
    with st.chat_message(role):
        # Filtramos para mostrar solo texto en el historial visual por ahora
        if message.parts[0].text:
             st.markdown(message.parts[0].text)

# 7. CHAT LÃ“GICA
if prompt := st.chat_input("Escribe tu pregunta sobre la imagen o el tema..."):
    
    # A. Mostrar mensaje usuario
    with st.chat_message("user"):
        st.markdown(prompt)
        if imagen_para_procesar:
            st.image(imagen_para_procesar, width=200) # Mostrar la foto en el chat tambiÃ©n
    
    # B. Enviar a la IA
    try:
        with st.chat_message("assistant"):
            with st.spinner("Analizando... ðŸ§ "):
                
                # --- AQUÃ ESTÃ LA MAGIA MULTIMODAL ---
                if imagen_para_procesar:
                    # Si hay imagen, enviamos una lista: [texto, imagen]
                    response = chat.send_message([prompt, imagen_para_procesar])
                else:
                    # Si no, enviamos solo texto
                    response = chat.send_message(prompt)
                
                st.markdown(response.text)
        
        # C. Actualizar memoria visual
        st.session_state.history = chat.history
        
    except Exception as e:
        st.error(f"Error: {e}")
